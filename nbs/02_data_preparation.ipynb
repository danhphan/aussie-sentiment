{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "discrete-gateway",
   "metadata": {},
   "source": [
    "### Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "incorporated-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "spare-stephen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 2), (19, 2))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "left = pd.read_pickle(\"../data/left.pkl\")\n",
    "right = pd.read_pickle(\"../data/right.pkl\")\n",
    "left.shape, right.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "comprehensive-chinese",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round1(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    text = re.sub('\\t', '', text)\n",
    "    text = re.sub('\\([^\\)]*\\)', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "spiritual-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "round1 = lambda x: clean_text_round1(x)\n",
    "left.content = left.content.apply(round1)\n",
    "right.content = right.content.apply(round1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "approved-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_round2(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('\\\\xa0', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\“', '', text)\n",
    "    text = re.sub('\\”', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "imperial-universe",
   "metadata": {},
   "outputs": [],
   "source": [
    "left.content = left.content.apply(round2)\n",
    "right.content = right.content.apply(round2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-integrity",
   "metadata": {},
   "source": [
    "##### Combine text together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "furnished-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_text(list_of_text):\n",
    "    '''Takes a list of text and combines them into one large chunk of text.'''\n",
    "    combined_text = ' '.join(list_of_text)\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "killing-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [combine_text(left.content.values), \n",
    "        combine_text(right.content.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "subsequent-spoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>hey we’ve got our first political sex scandal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>her names nicolle and shes quite a troll nicol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content\n",
       "left   hey we’ve got our first political sex scandal ...\n",
       "right  her names nicolle and shes quite a troll nicol..."
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data, columns=[\"content\"], index=[\"left\",\"right\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "mounted-blackberry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>wing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>hey we’ve got our first political sex scandal ...</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>her names nicolle and shes quite a troll nicol...</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content   wing\n",
       "left   hey we’ve got our first political sex scandal ...   left\n",
       "right  her names nicolle and shes quite a troll nicol...  right"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"wing\"] = [\"left\", \"right\"]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "aggressive-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as corpus\n",
    "data.to_pickle(\"../data/corpus.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-rocket",
   "metadata": {},
   "source": [
    "### Document-term matrix or Bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "twenty-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "invisible-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "data_cv = cv.fit_transform(data.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "exotic-treaty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aapi</th>\n",
       "      <th>aba</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abel</th>\n",
       "      <th>abest</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abortion</th>\n",
       "      <th>...</th>\n",
       "      <th>yorker</th>\n",
       "      <th>yorkers</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zero</th>\n",
       "      <th>zucker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>left</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 4827 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aapi  aba  abandon  abandoned  abel  abest  abilities  ability  able  \\\n",
       "left      0    1        1          0     1      0          0        2     2   \n",
       "right     2    0        0          1     0      1          1        0     3   \n",
       "\n",
       "       abortion  ...  yorker  yorkers  youd  youll  young  youre  youve  zeal  \\\n",
       "left          0  ...       0        0     0      0      3      0      0     0   \n",
       "right        10  ...       1        3     1      4      6      2      2     1   \n",
       "\n",
       "       zero  zucker  \n",
       "left      0       0  \n",
       "right     4       1  \n",
       "\n",
       "[2 rows x 4827 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dtm = pd.DataFrame(data_cv.toarray(),\n",
    "                        columns=cv.get_feature_names(),\n",
    "                        index=[\"left\", \"right\"])\n",
    "data_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "endless-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dtm.to_pickle(\"../data/docterm_matrix.pkl\")\n",
    "pickle.dump(cv, open(\"../data/cv.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-myanmar",
   "metadata": {},
   "source": [
    "### Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dense-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bizarre-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "gentle-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "right['wing'] = 'right'\n",
    "left['wing'] = 'left'\n",
    "data = pd.concat([right, left], ignore_index=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "historic-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = data.content.values\n",
    "train_y = data.wing.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "dental-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [nlp(text) for text in train_x]\n",
    "train_x_vecs = [x.vector for x in docs]\n",
    "len(train_x_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "recorded-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a SVM for classifying left/right wing\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "hundred-effort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm = svm.SVC(kernel='linear')\n",
    "clf_svm.fit(train_x_vecs, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "stable-course",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['right', 'right', 'right', 'right', 'right', 'right', 'right',\n",
       "       'right', 'right', 'right', 'right', 'right', 'right', 'right',\n",
       "       'right', 'right', 'right', 'right', 'right', 'right', 'right',\n",
       "       'right', 'right', 'right', 'right', 'right', 'right', 'right',\n",
       "       'right'], dtype=object)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test again\n",
    "test_x = train_x\n",
    "test_docs = [nlp(text) for text in test_x]\n",
    "test_x_word_vectors =  [x.vector for x in test_docs]\n",
    "\n",
    "clf_svm.predict(test_x_word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-determination",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "sharp-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "solid-peace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10626"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "words_left = word_tokenize(' '.join([s for s in left.content.values]))\n",
    "len(words_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "challenging-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_left = []\n",
    "for word in words_left:\n",
    "    stemmed_left.append(stemmer.stem(word))\n",
    "stemmed_left = \" \".join(stemmed_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-nursing",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "motivated-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "excessive-salmon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read the book'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = \"reading the books\"\n",
    "words = word_tokenize(phrase)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = []\n",
    "for word in words:\n",
    "  lemmatized_words.append(lemmatizer.lemmatize(word, pos='v'))\n",
    "\n",
    "\" \".join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-roman",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
